{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1752463365292,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "cXkb5H2a4R4U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7589,
     "status": "ok",
     "timestamp": 1752463372845,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "MZG5EK1e4jO1",
    "outputId": "509e9f53-7a6d-4127-9cad-a8ac1bc8b747"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\Pranav Desai\\Desktop\\Chronic Disease\\Augmented kidney_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1752463372922,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "f5aQFhQF4nUb"
   },
   "outputs": [],
   "source": [
    "X = df.drop(\"classification\", axis=1).values\n",
    "Y = df[\"classification\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1752463373036,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "oFatsfZ_Xywo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1752463373075,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "HzMG9wWa4nKE"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1752463373103,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "VlRcHKl04yH0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reshape to (samples, height, width, channels) to simulate image input\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1752463373105,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "c8LmThhovXtW"
   },
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1752463373171,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "anLTYSwTvdAe"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1752463373200,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "YFkOJz8441y7"
   },
   "outputs": [],
   "source": [
    "# STEP 4: Channel shuffle\n",
    "def channel_shuffle(x, groups):\n",
    "    batchsize, num_channels, length = x.size()\n",
    "    channels_per_group = num_channels // groups\n",
    "    x = x.view(batchsize, groups, channels_per_group, length)\n",
    "    x = x.transpose(1, 2).contiguous()\n",
    "    x = x.view(batchsize, -1, length)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1752463373716,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "ODqlAYnx6uoi"
   },
   "outputs": [],
   "source": [
    "\n",
    "# STEP 5: ShuffleBlock and Model\n",
    "class ShuffleBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, groups=2):\n",
    "        super(ShuffleBlock1D, self).__init__()\n",
    "        self.groups = groups\n",
    "        self.group_conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, groups=groups)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dwconv = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1, groups=out_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.group_conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=1, groups=groups)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.group_conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = channel_shuffle(x, self.groups)\n",
    "        x = self.dwconv(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.group_conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        return self.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1752463373718,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "aGj_83kDv4RM"
   },
   "outputs": [],
   "source": [
    "class ShuffleNet1D(nn.Module):\n",
    "    def __init__(self, input_channels=1, input_length=13, num_classes=2):\n",
    "        super(ShuffleNet1D, self).__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.stage1 = ShuffleBlock1D(32, 64)\n",
    "        self.stage2 = ShuffleBlock1D(64, 128)\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6248,
     "status": "ok",
     "timestamp": 1752463379967,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "hrVnT1q01JVy"
   },
   "outputs": [],
   "source": [
    "# STEP 6: Train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ShuffleNet1D().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46533,
     "status": "ok",
     "timestamp": 1752463426531,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "QMKD5QTI1OO5",
    "outputId": "e8662842-3799-480f-9e17-686478ef549f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.1171\n",
      "Epoch 2/20, Loss: 0.0076\n",
      "Epoch 3/20, Loss: 0.0037\n",
      "Epoch 4/20, Loss: 0.0030\n",
      "Epoch 5/20, Loss: 0.0009\n",
      "Epoch 6/20, Loss: 0.0005\n",
      "Epoch 7/20, Loss: 0.0061\n",
      "Epoch 8/20, Loss: 0.0006\n",
      "Epoch 9/20, Loss: 0.0003\n",
      "Epoch 10/20, Loss: 0.0002\n",
      "Epoch 11/20, Loss: 0.0001\n",
      "Epoch 12/20, Loss: 0.0001\n",
      "Epoch 13/20, Loss: 0.0001\n",
      "Epoch 14/20, Loss: 0.0001\n",
      "Epoch 15/20, Loss: 0.0002\n",
      "Epoch 16/20, Loss: 0.0059\n",
      "Epoch 17/20, Loss: 0.0036\n",
      "Epoch 18/20, Loss: 0.0009\n",
      "Epoch 19/20, Loss: 0.0002\n",
      "Epoch 20/20, Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/20, Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1752463426972,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "glrDQqN_1l_R",
    "outputId": "c24d43f5-ea2d-4a6b-eb01-02a8a33c5ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1225\n",
      "           1       1.00      1.00      1.00       775\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model.eval()\n",
    "preds, labels_all = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch = x_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        preds.extend(predicted.cpu().numpy())\n",
    "        labels_all.extend(y_batch.numpy())\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(labels_all, preds))\n",
    "print(classification_report(labels_all, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 43420,
     "status": "ok",
     "timestamp": 1752463470516,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "HVvKg-0M2BxJ",
    "outputId": "9bc20cc9-47c9-4747-cf59-05829a91bcc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\python\\lib\\site-packages (2.6.2)\n",
      "Requirement already satisfied: six~=1.15.0 in d:\\python\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in d:\\python\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in d:\\python\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in d:\\python\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in d:\\python\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in d:\\python\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in d:\\python\\lib\\site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in d:\\python\\lib\\site-packages (from tensorflow) (1.48.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in d:\\python\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in d:\\python\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in d:\\python\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in d:\\python\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in d:\\python\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in d:\\python\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: clang~=5.0 in d:\\python\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in d:\\python\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: gast==0.4.0 in d:\\python\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in d:\\python\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in d:\\python\\lib\\site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in d:\\python\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: cached-property in d:\\python\\lib\\site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\python\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\python\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in d:\\python\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\python\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\python\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\python\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\python\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\python\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (59.6.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\python\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\python\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\python\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\python\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\python\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: dataclasses in d:\\python\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\python\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\python\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\python\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4381,
     "status": "ok",
     "timestamp": 1752463474901,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "WzEqfk2n38sW",
    "outputId": "c96f6430-66be-4f57-c0e4-fc17769b0e67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thop in d:\\python\\lib\\site-packages (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch in d:\\python\\lib\\site-packages (from thop) (1.10.2)\n",
      "Requirement already satisfied: typing-extensions in d:\\python\\lib\\site-packages (from torch->thop) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in d:\\python\\lib\\site-packages (from torch->thop) (0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1752463474903,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "CFX--HyQiBpD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from thop import profile as thop_profile\n",
    "from torch.profiler import profile, ProfilerActivity\n",
    "\n",
    "def evaluate_pytorch_model_metrics(model, x_test, y_test, model_name=\"model_metrics\", device=None):\n",
    "    model.eval()\n",
    "    results = {}\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    x_test = x_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    # Accuracy\n",
    "    with torch.no_grad():\n",
    "        outputs = model(x_test)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = (predicted == y_test).float().mean().item()\n",
    "\n",
    "    results['accuracy'] = accuracy\n",
    "\n",
    "    # Inference time\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        model(x_test)\n",
    "    end_time = time.time()\n",
    "    results['inference_time_seconds'] = end_time - start_time\n",
    "\n",
    "    # Model size in bytes and MB\n",
    "    # Model size in bytes and MB\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pt\") as tmp:\n",
    "        temp_path = tmp.name  # Save the file path\n",
    "\n",
    "    torch.save(model.state_dict(), temp_path)\n",
    "\n",
    "    # Now the file is closed, safe to access and delete\n",
    "    size_bytes = os.path.getsize(temp_path)\n",
    "    results['model_size_bytes'] = size_bytes\n",
    "    results['model_size_MB'] = size_bytes / (1024 * 1024)\n",
    "\n",
    "    os.unlink(temp_path)  # Safe to delete now\n",
    "\n",
    "    # Parameter count\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    results['total_parameters'] = total_params\n",
    "\n",
    "    # FLOPs (optional basic estimate)\n",
    "    try:\n",
    "        from thop import profile as thop_profile\n",
    "        dummy_input = torch.randn(1, *x_test.shape[1:]).to(device)\n",
    "        flops, _ = thop_profile(model, inputs=(dummy_input,))\n",
    "        results['FLOPs'] = flops\n",
    "        results['GFLOPs'] = flops / 1e9\n",
    "    except:\n",
    "        results['FLOPs'] = \"Requires thop package\"\n",
    "        results['GFLOPs'] = \"Requires thop package\"\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752463474911,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "f_ebuDEM20DA",
    "outputId": "05bbe088-58b2-4628-8638-d9164eb2ffe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool1d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "{'accuracy': 1.0, 'inference_time_seconds': 0.09747886657714844, 'model_size_bytes': 92236, 'model_size_MB': 0.08796310424804688, 'total_parameters': 18114, 'FLOPs': 446592.0, 'GFLOPs': 0.000446592}\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_pytorch_model_metrics(model, X_test_tensor, y_test_tensor, model_name=\"shufflenet1d\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9fV_rx99zKZ"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1752463474913,
     "user": {
      "displayName": "DESAI PRANAV AVINASH",
      "userId": "15523395059269698347"
     },
     "user_tz": -330
    },
    "id": "xtu0r4gL7rjK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6jh1nvI4Adm"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
